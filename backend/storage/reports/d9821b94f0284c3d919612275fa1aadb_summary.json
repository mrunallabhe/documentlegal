{"case_id":"d9821b94f0284c3d919612275fa1aadb","generated_at":"2025-11-27T18:36:25.407451","timeline_events":1,"inconsistencies":0,"missing_evidence":["No witness statements found. Consider obtaining statements from witnesses and bystanders.","No CCTV footage or surveillance images found. Consider collecting CCTV from nearby locations.","Check for forensic reports (fingerprints, DNA analysis, blood spatter analysis).","Collect phone records and call logs if applicable.","Limited time coverage. Consider collecting evidence from extended time periods before and after the incident.","Verify alibis and cross-check with CCTV timestamps.","Obtain statements from neighbors and nearby residents.","No FIR (First Information Report) found. Ensure FIR is included in case files.","No medical reports found. If injuries occurred, obtain medical examination reports."],"report_path":"storage\\reports\\d9821b94f0284c3d919612275fa1aadb.pdf","preview":{"timeline":["Mrunal Labhe, A1 , 12\nPractical 2:Aim:Write a Python NLTK program to split the text from genesis corpus\nand display it into a list of words. Remove the Punctuation and Stopwords from the\ngiven text and perform Stemming and POS tagging\nTheory:\nNatural Language Processing (NLP) enables computers to process, analyze, and\nunderstand human language. This lab employs the NLTK (Natural Language Toolkit)\nlibrary in Python for core NLP tasks:\n● Tokenization divides raw text into individual units (words)...."],"inconsistencies":[],"extracted_content":[{"file_type":"document","classification":{"label":"police_memo","confidence":0.7702805399894714,"method":"BERT"},"extracted_text":"Mrunal Labhe, A1 , 12\nPractical 2:Aim:Write a Python NLTK program to split the text from genesis corpus\nand display it into a list of words. Remove the Punctuation and Stopwords from the\ngiven text and perform Stemming and POS tagging\nTheory:\nNatural Language Processing (NLP) enables computers to process, analyze, and\nunderstand human language. This lab employs the NLTK (Natural Language Toolkit)\nlibrary in Python for core NLP tasks:\n● Tokenization divides raw text into individual units (words).\n● Stopword Removal eliminates common, non-informative words.\n● Stemming reduces words to their root form for normalization.\n● POS Tagging assigns parts of speech (like noun, verb) to each word.\n● Dependency Parsing analyzes grammatical structure, identifying relationships\nwithin the sentence.\nThese steps are foundational for advanced text analysis, search, and AI language\napplications.\nCode:\n#importing all the dependencies\nimport nltk\nfrom nltk.corpus import genesis, stopwords\nfrom nltk.tokenize import word_tokenize , sent_tokenize\nfrom nltk.stem import SnowballStemmer\nfrom nltk import pos_tag\nimport string\nnltk.download('genesis')\nnltk.download('punkt_tab')\nnltk.download('stopwords')\nnltk.download('averaged_perceptron_tagger_eng')\n#loading the dataset :\ngenesis_corpus = genesis.raw()\nsentences = sent_tokenize(genesis_corpus)\nprint(\"Number of senteces found in the genesis_corpus: \", len(sentences))\n# Removing punctuation and stop words and doing stemming:\nstop_words = set(stopwords.words('english'))\n1\nMrunal Labhe, A1 , 12\nstemmer = SnowballStemmer('english')\n# preprocessing\ndef preprocess(sentence):\nwords = word_tokenize(sentence)\nwords = [word for word in words if word.lower() not in stop_words]\nwords = [word for word in words if word not in string.punctuation]\nwords= [stemmer.stem(word) for word in words]\ntagged_words = pos_tag(words)\nreturn tagged_words\n#calling the function\nfor sentence in sentences: tagged_words = preprocess(sentence)[:10]\nprint(tagged_words, \"\\n\")\nimport spacy.cli\nspacy.cli.download(\"en_core_web_sm\")\nimport spacy\nfrom spacy import displacy\nnlp = spacy.load('en_core_web_sm')\ntext = \"Teaching NLP requires understanding both syntax rules and\nsemantic analysis\"\ndoc = nlp(text)\ndisplacy.render(doc ,style='dep')\nOutput screenshots:\n1.1 Printing the tagged words:\nThe tagged words are printed after the removal of stop words , all the punctuation and\nstemming.\n2\nMrunal Labhe, A1 , 12\n\\1.2 Display figure of words and relationships\nDataset or Resources Used:\n● NLTK Genesis Corpus: A publicly available text dataset from the Natural\nLanguage Toolkit.\n● NLTK Library: Python package for natural language processing.\n:\nProcedure Followed\n1. Load and display text from the Genesis corpus with NLTK.\n2. Tokenize the text into a list of words.\n3. Remove punctuation and stopwords.\n4. Apply stemming to tokens.\n5. Perform POS tagging.\n6. Visualize grammatical structure using a dependency parser.\n7. Provide annotated code and explanations.\nDate of Performance: 8th August 2025\n3\nMrunal Labhe, A1 , 12\nViva Questions with Answers\n1. What is the purpose of removing stopwords in NLP?\n● Answer: Stopwords are common words (like \"the\", \"is\") that do not\ncontribute significant meaning to text analysis. Removing them reduces\nnoise and improves processing efficiency.\n2. How does stemming differ from lemmatization?\n● Answer: Stemming crudely removes affixes to reduce words to a root form,\nsometimes producing non-words (like \"run\" from \"running\").\nLemmatization finds the dictionary root of a word, ensuring valid words.\n3. What is POS tagging and why is it important?\n● Answer: POS tagging assigns grammatical roles (noun, verb, etc.) to each\nword, enabling syntactic and semantic understanding, and supports tasks\nlike parsing and named entity recognition.\n4. Explain the purpose of a dependency parser.\n● Answer: A dependency parser maps out grammatical relationships\nbetween words, showing how they connect. This helps understand\nsentence structure, such as which word is the subject or object.\n5. What does the NLTK Genesis corpus contain?\n● Answer: The Genesis corpus contains the text of the biblical Book of\nGenesis in several languages, used for linguistic and computational\nlanguage processing studies.\n4","entities":[{"entity":"A1","label":"PRODUCT","start":14,"end":16},{"entity":"12","label":"CARDINAL","start":19,"end":21},{"entity":"NLTK","label":"PERSON","start":53,"end":57},{"entity":"Stopwords","label":"PERSON","start":168,"end":177},{"entity":"Natural Language Processing (","label":"WORK_OF_ART","start":243,"end":272},{"entity":"NLP","label":"ORG","start":272,"end":275},{"entity":"NLP","label":"ORG","start":427,"end":430},{"entity":"Stopword Removal","label":"PERSON","start":503,"end":519},{"entity":"AI","label":"ORG","start":864,"end":866},{"entity":"#","label":"CARDINAL","start":896,"end":897},{"entity":"SnowballStemmer","label":"ORG","start":1061,"end":1076},{"entity":"nltk.download('averaged_perceptron_tagger_eng","label":"ORG","start":1195,"end":1240},{"entity":"1","label":"CARDINAL","start":1516,"end":1517},{"entity":"A1","label":"PRODUCT","start":1532,"end":1534},{"entity":"12","label":"CARDINAL","start":1537,"end":1539},{"entity":"#","label":"CARDINAL","start":1881,"end":1882},{"entity":"\\n","label":"WORK_OF_ART","start":1992,"end":1994},{"entity":"NLP","label":"ORG","start":2143,"end":2146},{"entity":"style='dep'","label":"ORG","start":2248,"end":2259},{"entity":"1.1","label":"CARDINAL","start":2281,"end":2284},{"entity":"2","label":"CARDINAL","start":2409,"end":2410},{"entity":"A1","label":"PRODUCT","start":2425,"end":2427},{"entity":"12","label":"CARDINAL","start":2430,"end":2432},{"entity":"Dataset","label":"ORG","start":2480,"end":2487},{"entity":"1","label":"CARDINAL","start":2684,"end":2685},{"entity":"Genesis","label":"ORG","start":2718,"end":2725},{"entity":"NLTK","label":"ORG","start":2738,"end":2742},{"entity":"2","label":"CARDINAL","start":2744,"end":2745},{"entity":"3","label":"CARDINAL","start":2787,"end":2788},{"entity":"4","label":"CARDINAL","start":2824,"end":2825},{"entity":"5","label":"CARDINAL","start":2853,"end":2854},{"entity":"6","label":"CARDINAL","start":2877,"end":2878},{"entity":"7","label":"CARDINAL","start":2939,"end":2940},{"entity":"8th August 2025","label":"DATE","start":3004,"end":3019},{"entity":"3","label":"CARDINAL","start":3020,"end":3021},{"entity":"Mrunal Labhe","label":"ORG","start":3022,"end":3034},{"entity":"A1","label":"PRODUCT","start":3036,"end":3038},{"entity":"12","label":"CARDINAL","start":3041,"end":3043},{"entity":"1","label":"CARDINAL","start":3072,"end":3073},{"entity":"NLP","label":"ORG","start":3120,"end":3123},{"entity":"2","label":"CARDINAL","start":3306,"end":3307},{"entity":"Lemmatization","label":"WORK_OF_ART","start":3488,"end":3501},{"entity":"3","label":"CARDINAL","start":3561,"end":3562},{"entity":"4","label":"CARDINAL","start":3799,"end":3800},{"entity":"5","label":"CARDINAL","start":4039,"end":4040},{"entity":"Genesis","label":"ORG","start":4099,"end":4106},{"entity":"Book of\nGenesis","label":"WORK_OF_ART","start":4148,"end":4163},{"entity":"4","label":"CARDINAL","start":4253,"end":4254}],"objects_detected":[],"ocr_text":"","timestamps":[],"locations":[],"summary":"Mrunal Labhe, A1 , 12\nPractical 2:Aim:Write a Python NLTK program to split the text from genesis corpus\nand display it into a list of words. Remove the Punctuation and Stopwords from the\ngiven text and perform Stemming and POS tagging\nTheory:\nNatural Language Processing (NLP) enables computers to process, analyze, and\nunderstand human language. This lab employs the NLTK (Natural Language Toolkit)\nlibrary in Python for core NLP tasks:\n● Tokenization divides raw text into individual units (words)....","dates":[],"events":[]}]}}